{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Estimating prices with OpenAI-proxy sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install openai_proxy package into your environment\n",
    "%%capture\n",
    "!pip install --upgrade openai_proxy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openai_proxy\n",
    "import os\n",
    "\n",
    "# For UPENN students\n",
    "# openai_proxy.username = \"kairos\"\n",
    "# openai_proxy.course_id = \"8000\"\n",
    "# openai_proxy.access_key = \"O6rbLM3-yYcwS5GaWZEghA\"\n",
    "# openai_proxy.access_token = \"4q-_apNm72sGENVtYtcCXAnC7jEGnIUZfylHbEAEdFQ\"\n",
    "\n",
    "# PUBLIC users\n",
    "openai_proxy.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a polite but sarcastic chat bot\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What can you say about the Aztec Empire. Thousands of years\"\n",
    "        }],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = openai.Image.create(\n",
    "    prompt=\"flying monkeys in nyc\",\n",
    "    n=2,\n",
    "    size=\"1024x1024\",\n",
    ")\n",
    "print(response_2[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the prices of the first response\n",
    "print(\"response_price\", openai_proxy.Price.from_response(response))\n",
    "print(\"response_2_price\", openai_proxy.Price.from_response(response_2))\n",
    "\n",
    "# To get the prices of a list of responses\n",
    "print(\"response_list_price\", openai_proxy.Price.from_list_response([response, response_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum price of a request BEFORE sending\n",
    "response = openai_proxy.ChatCompletion.price(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a polite but sarcastic chat bot\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What can you say about the Aztec Empire. Thousands of years\"\n",
    "        }],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "print(response['price'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More supported uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = openai_proxy.Completion.price(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=\"The average word contains about 1.3 tokens. But most words contain a single token and niche, longer words contain more tokens like tarantula contains 3\",\n",
    "    max_tokens=200,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "print(response['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "response = openai_proxy.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=\"What can you say about the Aztec Empire. Thousands of years\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=200,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=[\"###\", '\\n'],\n",
    "    n=2\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['text'])\n",
    "print(response['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "response = openai_proxy.Embedding.create(\n",
    "    phrases=[\n",
    "        \"This is the first phrase\",\n",
    "        \"This is the second slightly longer phrase\",\n",
    "        \"This is the third phrase\",\n",
    "    ]\n",
    ")\n",
    "print(response)\n",
    "print(response['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "response = openai_proxy.ChatCompletion.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a polite but sarcastic chat bot\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What can you say about the Aztec Empire. Thousands of years\"\n",
    "        }],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "print(response['choices'][0]['message']['content'])\n",
    "print(response['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "response_2 = openai_proxy.Image.create(\n",
    "    prompt=\"flying monkeys in nyc\",\n",
    "    n=2,\n",
    "    size=\"1024x1024\",\n",
    ")\n",
    "print(response_2[\"data\"])\n",
    "print(response_2['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# To get the price of all the requests sent since last package import\n",
    "print(\"session_price\", openai_proxy.session_price)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2fe5bca17fb879a08cf6fd313262bb7ad63d5ffec61276eaa38c8f08b877b591"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
